{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53baceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/rkube/repos/frnn-loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d895dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import unittest\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "import h5py\n",
    "\n",
    "from frnn_loader.backends.fetchers import fetcher_d3d_v1\n",
    "from frnn_loader.primitives.resamplers import resampler_causal\n",
    "from frnn_loader.backends.backend_hdf5 import backend_hdf5\n",
    "from frnn_loader.primitives.signal import signal_0d\n",
    "from frnn_loader.loaders.frnn_dataset_disk import shot_dataset_disk\n",
    "from frnn_loader.utils.errors import BadDownloadError\n",
    "\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7567d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shotlist_clear =  [167475, 167481]\n",
      "shotlist_disrupt =  [167480, 167487]\n",
      "ttd =  2.159\n"
     ]
    }
   ],
   "source": [
    "root = tempfile.mkdtemp(dir=\"/home/rkube/tmp\")\n",
    "basedir = \"/projects/FRNN/shot_lists\"\n",
    "shotlist_clear = []\n",
    "\n",
    "count = 2\n",
    "i = 0\n",
    "\n",
    "with open(join(basedir, \"d3d_clear_100.txt\"), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "        shotlist_clear.append(shotnr)\n",
    "\n",
    "        i += 1\n",
    "        if i >= count:\n",
    "            break\n",
    "\n",
    "shotlist_disrupt = []\n",
    "ttd_list = []\n",
    "i = 0\n",
    "with open(join(basedir, \"d3d_disrupt_100.txt\"), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "        shotlist_disrupt.append(shotnr)\n",
    "        ttd_list.append(ttd)\n",
    "\n",
    "        i += 1\n",
    "        if i >= count:\n",
    "            break\n",
    "\n",
    "print(\"shotlist_clear = \", shotlist_clear)\n",
    "print(\"shotlist_disrupt = \", shotlist_disrupt)\n",
    "print(\"ttd = \", ttd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628d75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Instantiate datasets that include TTD transformation\"\"\"\n",
    "\n",
    "my_resampler = resampler_causal(0.0, 2e3, 1e0)\n",
    "\n",
    "# Instantiate a file backend\n",
    "my_backend_file = backend_hdf5(\"/home/rkube/datasets/frnn/\")\n",
    "my_fetcher = fetcher_d3d_v1()\n",
    "root = root\n",
    "\n",
    "signal_fs07 = signal_0d(\"fs07\")\n",
    "signal_q95 = signal_0d(\"q95\")\n",
    "signal_pinj = signal_0d(\"bmspinj\")\n",
    "\n",
    "ds_clear_list = []\n",
    "for shotnr in shotlist_clear:\n",
    "    ds = shot_dataset_disk(shotnr, \n",
    "                           predictors=[signal_fs07, signal_q95], \n",
    "                           resampler=my_resampler, \n",
    "                           backend_file=my_backend_file, \n",
    "                           fetcher=my_fetcher, \n",
    "                           root=root,\n",
    "                           download=True,\n",
    "                           dtype=torch.float32)\n",
    "\n",
    "    ds_clear_list.append(ds)\n",
    "    \n",
    "ds_disrupt_list = []\n",
    "for shotnr in shotlist_disrupt:\n",
    "    ds = shot_dataset_disk(shotnr, \n",
    "                           predictors=[signal_fs07, signal_q95], \n",
    "                           resampler=my_resampler, \n",
    "                           backend_file=my_backend_file, \n",
    "                           fetcher=my_fetcher, \n",
    "                           root=root,\n",
    "                           download=True,\n",
    "                           dtype=torch.float32)\n",
    "\n",
    "    ds_disrupt_list.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2c5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_c = ds_clear_list[0]\n",
    "ds_d = ds_disrupt_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3c4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(ds_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f6a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_clear_list[0]\n",
    "idx = 0\n",
    "output = torch.zeros(ds.sum_all_channels, dtype=ds.dtype)\n",
    "current_ch = 0\n",
    "with h5py.File(ds.tmp_fname, \"r\") as fp:\n",
    "    for pred in ds.predictors:\n",
    "        tb = fp[f\"/transformed/{pred.tag}_trf\"][\"timebase\"]\n",
    "        data = fp[f\"/transformed/{pred.tag}_trf\"][\"signal_data\"]\n",
    "\n",
    "#     # Access pattern for 0d signals\n",
    "        if isinstance(pred, signal_0d):\n",
    "            output[current_ch] = float(data[idx][0])\n",
    "            \n",
    "        current_ch += pred.num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c2cf097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the future we may want to use this approach\n",
    "# https://discuss.pytorch.org/t/dataloader-sample-by-slices-from-dataset/113005/5\n",
    "# dataset = MyDataset()\n",
    "# sampler = data.BatchSampler(data.RandomSampler(dataset), 4, False)\n",
    "# loader  = data.DataLoader(dataset, sampler=sampler, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe0e8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on-line formulations for standard deviation\n",
    "# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
    "\n",
    "# For a new value newValue, compute the new count, new mean, the new M2.\n",
    "# mean accumulates the mean of the entire dataset\n",
    "# M2 aggregates the squared distance from the mean\n",
    "# count aggregates the number of samples seen so far\n",
    "def update(existingAggregate, newValue):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    count += 1\n",
    "    delta = newValue - mean\n",
    "    mean += delta / count\n",
    "    delta2 = newValue - mean\n",
    "    M2 += delta * delta2\n",
    "    return (count, mean, M2)\n",
    "\n",
    "# Retrieve the mean, variance and sample variance from an aggregate\n",
    "def finalize(existingAggregate):\n",
    "    (count, mean, M2) = existingAggregate\n",
    "    if count < 2:\n",
    "        return float(\"nan\")\n",
    "    else:\n",
    "        (mean, variance, sampleVariance) = (mean, M2 / count, M2 / (count - 1))\n",
    "        return (mean, variance, sampleVariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4366f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate:\n",
    "    \"\"\"On-line formulations for standard deviation\n",
    "        \n",
    "        https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, shotnr, tag):\n",
    "        \"\"\"Initializes class\"\"\"\n",
    "        self.shotnr = shotnr\n",
    "        self.tag = tag\n",
    "        self.count = 0\n",
    "        self.mean = 0.0\n",
    "        self.M2 = 0.0\n",
    "        self.variance = float(\"nan\")\n",
    "        self.finalized = False\n",
    "        \n",
    "    def update(self, new_val):\n",
    "        \"\"\"Online update of the statistics\"\"\"\n",
    "        self.count += 1\n",
    "        delta = new_val - self.mean\n",
    "        self.mean += delta / self.count\n",
    "        delta2 = new_val - self.mean\n",
    "        self.M2 += delta * delta2\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"aggregate {self.tag} - mean={self.mean:e}, variance={self.variance:e} - finalized={self.finalized} count={self.count}\"\n",
    "        \n",
    "    def finalize(self):\n",
    "        \"\"\"Transform M2 to variance\"\"\"\n",
    "        if self.count < 2:\n",
    "            return float(\"nan\")\n",
    "        else:\n",
    "            self.variance = self.M2 / self.count\n",
    "            self.finalized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a41767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(ds, Q):\n",
    "    \n",
    "    # Create a list of aggregators, one for each predictor\n",
    "    agg_list = [aggregate(ds.shotnr, pred.tag) for pred in ds.predictors]    \n",
    "    \n",
    "    # Iterate over dataset \n",
    "    for i in range(len(ds)):\n",
    "        vals = ds[i]\n",
    "        f, q = vals\n",
    "        \n",
    "        # Update the aggregators, one-by-one\n",
    "        for val, agg in zip(ds[i], agg_list):\n",
    "            agg.update(val.item())\n",
    "\n",
    "    # Finalize the aggregators\n",
    "    for agg in agg_list:\n",
    "        agg.finalize()\n",
    "    \n",
    "    # And put them in a queue\n",
    "    Q.put(agg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091c57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mp.Queue()\n",
    "processes = []\n",
    "\n",
    "for ds in ds_clear_list:\n",
    "    p = mp.Process(target=calc_stats, args=(ds, Q))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "    \n",
    "for p in processes:\n",
    "    p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "426b68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        item = Q.get_nowait()\n",
    "    except:\n",
    "        break\n",
    "    rvs.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c80c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fs07'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs[0][0].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9e6b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.aggregate object at 0x20008e245df0>, <__main__.aggregate object at 0x20008e23e160>]\n",
      "[<__main__.aggregate object at 0x20008e25fd90>, <__main__.aggregate object at 0x200183e84040>]\n"
     ]
    }
   ],
   "source": [
    "# compile all aggregators for a single predictor\n",
    "agg_fs07 = [rv[0] for rv in rvs if rv[0].tag == \"fs07\"]\n",
    "print(agg_fs07)\n",
    "\n",
    "# compile all aggregators for a single predictor\n",
    "agg_q95 = [rv[1] for rv in rvs if rv[1].tag == \"q95\"]\n",
    "print(agg_q95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6f42f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate fs07 - mean=2.176951e+13, variance=6.708551e+27 - finalized=True count=2000\n",
      "aggregate fs07 - mean=2.999673e+13, variance=5.274382e+28 - finalized=True count=2000\n"
     ]
    }
   ],
   "source": [
    "print(agg_fs07[0])\n",
    "print(agg_fs07[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0745dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 6.836050e+00, 5.380592e+00\n",
      "4000 6.815474e+00, 5.204656e+00\n"
     ]
    }
   ],
   "source": [
    "# Now reduce the aggregators, one-by-one over each shot in the list\n",
    "\n",
    "n_run = 0\n",
    "xbar_run = 0.0\n",
    "M2_run = 0.0\n",
    "\n",
    "\n",
    "def update_running_stats(n_run, xbar_run, M2_run, agg):\n",
    "    n_b = agg.count\n",
    "    delta = agg.mean - xbar_run\n",
    "    xbar_run = (xbar_run * n_run + agg.mean * agg.count) / (n_run + n_b)\n",
    "    M2_run = M2_run + agg.M2 + delta * delta * n_run * agg.count / (n_run + agg.count)\n",
    "    n_run += agg.count\n",
    "\n",
    "    return (n_run, xbar_run, M2_run)\n",
    "\n",
    "n_run, xbar_run, M2_run = update_running_stats(n_run, xbar_run, M2_run, agg_q95[0])\n",
    "print(f\"{n_run} {xbar_run:e}, {M2_run/n_run:e}\")\n",
    "\n",
    "n_run, xbar_run, M2_run = update_running_stats(n_run, xbar_run, M2_run, agg_q95[1])\n",
    "print(f\"{n_run} {xbar_run:e}, {M2_run/n_run:e}\")\n",
    "\n",
    "\n",
    "    \n",
    "# Seed with first element\n",
    "#na = agg_fs07[0].count\n",
    "#nb = agg_fs07[1].count\n",
    "#delta = agg_fs07[1].mean - agg_fs07[0].mean\n",
    "#xbar_AB = (agg_fs07[0].mean * na + agg_fs07[1].mean * nb) / (na + nb)\n",
    "#M2AB = agg_fs07[0].M2 + agg_fs07[1].M2 + delta * delta * na * nb / (na + nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b5e762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2.176951e+13, 6.708551e+27\n",
      "4000 2.588312e+13, 2.974311e+28\n"
     ]
    }
   ],
   "source": [
    "n_run = 0\n",
    "xbar_run = 0.0\n",
    "M2_run = 0.0\n",
    "\n",
    "\n",
    "def update_running_stats(n_run, xbar_run, M2_run, agg):\n",
    "    n_b = agg.count\n",
    "    delta = agg.mean - xbar_run\n",
    "    xbar_run = (xbar_run * n_run + agg.mean * agg.count) / (n_run + n_b)\n",
    "    M2_run = M2_run + agg.M2 + delta * delta * n_run * agg.count / (n_run + agg.count)\n",
    "    n_run += agg.count\n",
    "\n",
    "    return (n_run, xbar_run, M2_run)\n",
    "\n",
    "n_run, xbar_run, M2_run = update_running_stats(n_run, xbar_run, M2_run, agg_fs07[0])\n",
    "print(f\"{n_run} {xbar_run:e}, {M2_run/n_run:e}\")\n",
    "\n",
    "n_run, xbar_run, M2_run = update_running_stats(n_run, xbar_run, M2_run, agg_fs07[1])\n",
    "print(f\"{n_run} {xbar_run:e}, {M2_run/n_run:e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3953409",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agg_fs07_shot1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now test the parallel algorithm\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#cite_note-:1-3\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m M2A \u001b[38;5;241m=\u001b[39m \u001b[43magg_fs07_shot1\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      4\u001b[0m M2B \u001b[38;5;241m=\u001b[39m agg_fs07_shot2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(agg_fs07_shot1[\u001b[38;5;241m0\u001b[39m], agg_fs07_shot2[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agg_fs07_shot1' is not defined"
     ]
    }
   ],
   "source": [
    "# Now test the parallel algorithm\n",
    "# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#cite_note-:1-3\n",
    "M2A = agg_fs07_shot1[1] * 2000\n",
    "M2B = agg_fs07_shot2[1] * 2000\n",
    "\n",
    "print(agg_fs07_shot1[0], agg_fs07_shot2[0])\n",
    "\n",
    "\n",
    "n_AB = 2000 + 2000\n",
    "delta = agg_fs07_shot2[0] - agg_fs07_shot1[0]\n",
    "M2AB = M2A + M2B + delta * delta * 2000 * 2000 / 4000\n",
    "\n",
    "print(M2AB / (4000 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d0651cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate stats of fs07 in first shot\n",
    "agg_fs07_shot1 = [0, 0.0, 0.0]\n",
    "agg_fs07_shot1_class = aggregate(shotlist_clear[0], \"fs07\")\n",
    "\n",
    "# Aggregate stats of fs07 in second shot\n",
    "agg_fs07_shot2 = [0, 0.0, 0.0]\n",
    "agg_fs07_shot2_class = aggregate(shotlist_clear[1], \"fs07\")\n",
    "# Aggregate stats of q95 in first\n",
    "agg_q95_shot1 = [0, 0.0, 0.0]\n",
    "agg_q95_shot1_class = aggregate(shotlist_clear[0], \"q95\")\n",
    "# Aggregate stats of q95 in second shot\n",
    "agg_q95_shot2 = [0, 0.0, 0.0]\n",
    "agg_q95_shot2_class = aggregate(shotlist_clear[1], \"q95\")\n",
    "\n",
    "all_vals_shot1 = torch.zeros((2000, 2))\n",
    "all_vals_shot2 = torch.zeros((2000, 2))\n",
    "\n",
    "\n",
    "ds = ds_clear_list[0]\n",
    "for i in range(len(ds)):\n",
    "    vals = ds[i]\n",
    "    f, q = vals\n",
    "\n",
    "    agg_fs07_shot1 = update(agg_fs07_shot1, f.item())\n",
    "    agg_fs07_shot1_class.update(f.item())\n",
    "    \n",
    "    agg_q95_shot1 = update(agg_q95_shot1, q.item())\n",
    "    agg_q95_shot1_class.update(q.item())\n",
    "    \n",
    "    all_vals_shot1[i, 0] = f.item()\n",
    "    all_vals_shot1[i, 1] = q.item()\n",
    "    \n",
    "agg_fs07_shot1 = finalize(agg_fs07_shot1)\n",
    "agg_fs07_shot1_class.finalize()\n",
    "agg_q95_shot1 = finalize(agg_q95_shot1)\n",
    "agg_q95_shot1_class.finalize()\n",
    "\n",
    "ds = ds_clear_list[1]\n",
    "for i in range(len(ds)):\n",
    "    vals = ds[i]\n",
    "    f, q = vals\n",
    "\n",
    "    agg_fs07_shot2 = update(agg_fs07_shot2, f.item())\n",
    "    agg_fs07_shot2_class.update(f.item())\n",
    "\n",
    "    agg_q95_shot2 = update(agg_q95_shot2, q.item())\n",
    "    agg_q95_shot1_class.update(q.item())\n",
    "\n",
    "    \n",
    "    all_vals_shot2[i, 0] = f.item()\n",
    "    all_vals_shot2[i, 1] = q.item()\n",
    "    \n",
    "agg_fs07_shot2 = finalize(agg_fs07_shot2)\n",
    "agg_fs07_shot2_class.finalize()\n",
    "agg_q95_shot2 = finalize(agg_q95_shot2)\n",
    "agg_q95_shot1_class.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c4c442bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21769514773938.17, 6.708550972890995e+27, 6.711906926354173e+27)\n",
      "21769514773938.17 6.708550972890995e+27\n",
      "tensor(2.1770e+13) tensor(6.7119e+27)\n",
      "(6.836049656867986, 5.380592132257209, 5.383283774144281)\n",
      "tensor(6.8361) tensor(5.3833)\n",
      "(29996728662872.1, 5.2743823441884055e+28, 5.277020854615713e+28)\n",
      "tensor(2.9997e+13) tensor(5.2770e+28)\n",
      "(6.794898147583008, 5.0278727610423966, 5.030387955019907)\n",
      "tensor(6.7949) tensor(5.0304)\n"
     ]
    }
   ],
   "source": [
    "print(agg_fs07_shot1)\n",
    "print(agg_fs07_shot1_class.mean, agg_fs07_shot1_class.variance)\n",
    "print(all_vals_shot1[:,0].mean(), all_vals_shot1[:, 0].var())\n",
    "\n",
    "print(agg_q95_shot1)\n",
    "print(all_vals_shot1[:,1].mean(), all_vals_shot1[:, 1].var())\n",
    "\n",
    "print(agg_fs07_shot2)\n",
    "print(all_vals_shot2[:,0].mean(), all_vals_shot2[:, 0].var())\n",
    "\n",
    "print(agg_q95_shot2)\n",
    "print(all_vals_shot2[:,1].mean(), all_vals_shot2[:, 1].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e7418f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.205957297653324\n"
     ]
    }
   ],
   "source": [
    "# Now test the parallel algorithm\n",
    "# https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#cite_note-:1-3\n",
    "\n",
    "n_AB = 2000 + 2000\n",
    "delta = agg_q95_shot2[0] - agg_q95_shot1[0]\n",
    "xbar_AB = agg_q95_shot1[0] + delta * 2000 * 2000 / 4000\n",
    "M2A = agg_q95_shot1[1] * 2000\n",
    "M2B = agg_q95_shot2[1] * 2000\n",
    "M2AB = M2A + M2B + delta * delta * 2000 * 2000 / 4000\n",
    "\n",
    "print(M2AB / (4000 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c7028734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5883e+13, 6.8155e+00])\n",
      "tensor([2.9751e+28, 5.2060e+00])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([all_vals_shot1, all_vals_shot2]).mean(axis=0))\n",
    "print(torch.cat([all_vals_shot1, all_vals_shot2]).var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac404f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff676d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b339e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
